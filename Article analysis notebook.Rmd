---
title: "Article Analysis Notebook"
author: "Maria C. Codlin"
output:
  pdf_document: default
  html_notebook: default
---
###Table of contents?

###Introduction to this document, the contents, and the article.

First I modified the files slightly to import with curl, as it refused to bring in the header names with certain symbols in (it worked fine importing from local repo). 


To start with a blank slate
```{r clear workspace}
rm(list=ls())
```


#Step 1. Load packages and data
Before I run any parts of the analysis, I load all the packages I use in this file
```{r load libraries}
require(dplyr)
require(ggplot2)
require(stringr)
require(plotrix) #to calculate standard error
require(qwraps2)
```
First in excel, I deleted two rows of non-table data, i.e. title, and a note, and saved the file (S2_Table) as a CSV in the project directory. Then I read it into R and converted it to a table using dplyr. I trimed white space at beginnings and ends of things where there shouldn't be any, and kept strings as is to avoid issues later down the line. 
```{r readfile arch}
library(curl)
f <- curl("https://raw.githubusercontent.com/mazattack/Article-analysis/master/S2_Table.csv")
iso_total <- read.csv(f, header = TRUE, stringsAsFactors = FALSE, strip.white=TRUE)
iso_total<-tbl_df(iso_total)
head(iso_total)
str(iso_total)
```
```{r readfile modern}
f <- curl("https://raw.githubusercontent.com/mazattack/Article-analysis/master/S1_Table.csv")
modern<-read.csv(f, header=TRUE, sep = ",", skip=0, strip.white=TRUE, stringsAsFactors = FALSE) #here I used skip=3 to skip the first 3 rows before the data started
modern<-tbl_df(modern)
head(modern)
str(modern)
```

To make life easier, I changed the names of two key variables. First I tried 18O and 13C as the variable names, but it threw me an error, I think by starting with a number. 
```{r rename}
names(iso_total)[12]<-"C13ap" #I used names(iso_total) to get the position of these for renaming
names(iso_total)[13]<-"O18ap"
names(modern)[10]<-"modC13"
names(modern)[11]<-"modO18"
```


#Step 2: Remove of samples potentially affected by diagenisis and summarize data to check against means presented in the article 

In this article, they tested a random sample (n=101) of bone for potential post-depositional alteration to the mineral structure.Using FTIR, they tested the carbonate to phospate ratios (C/P) and infrared splitting factor (IR-SF) using FTIR and removed samples which fell outside of the expected ranges of 0.1 and 0.5 for C/P and 2.0 and 4.0 for IR-SF. The samples that they removed are marked in grey in the supplimentary data. 

Here, I used the filter function to select only those rows where C/P and IR-SF fell within the expected ranges, and saved this as a new dataset "iso". I also needed to make sure the rows with NA values were still included, since only a random sample was analysed. I did this using the | notation which functions like "OR". Since the FTIR analysis returned both C/P and IR-SF values, I only need to include one is.na function here. I also excluded an outlier with an extremely low delta O18 that they excluded by converting this number to NA, as the samples delta C13 value was still incorperated in the analysis.
```{r filter out diagenisis}
#to filter out only Lepus and Sylvilagus genus, I first needed to define the column as a factor
iso_total$Genus<-as.factor(iso_total$Genus)
iso<-filter(iso_total, (Genus=="Lepus" | Genus=="Sylvilagus") & between (C.P, 0.1, 0.5)&between (IR.SF, 2.0, 4.0) | (is.na(IR.SF))) #brackets around the Genus filter were important here, otherwise the | worked on everything that came after
iso$O18ap[iso$O18ap==11.9]<-NA #couldn't figure out how to get this to work with dplyr or chaining
iso            
```

"δ13Capatite = -7.8 ± 2.4‰(N = 114, 1 S.D.) and δ18Oapatite = 26.0‰(N = 113, 1 S.D.). The modern reference specimens exhibited
mean values of δ13Capatite = -12.4 ± 1.8‰(N = 13, 1 S.D.) and δ18Oapatite = 26.1‰± 1.4 (N = 13, 1 S.D.)."(Somerville et al. 2016:10). *I also note that they should have used "n" here*

Note: the first time I tried this it was not a match and so I realised I needed to keep the na values in the filter above. The second time it was also not correct so I added two lines to count the number of values in the two columns of interest to see if the sample sizes match. I noted the single value from delta O18 to remove but I still have one extra row in there than their sample number. I checked on the excel, and there is no evidence of this extra row that they excluded. I took a guess that this may have been a species listed in the spreadsheet as Lepus? and removal of this specimen now produces averages that match the data presented in the article. 

```{r sum_table}
my_sum <- 
  list("Archaeological samples" = 
         list("δC13 mean" = ~ mean(C13ap, na.rm=TRUE),
              "δC13 sd" = ~ sd(C13ap, na.rm=TRUE),
              "δO18 mean" = ~ mean(O18ap, na.rm=TRUE),
              "δO18 sd" = ~ sd(O18ap, na.rm=TRUE)),
       "Modern samples" = 
         list("δC13 mean" = ~ mean(modC13, na.rm=TRUE),
              "δC13 sd" = ~ sd(modC13, na.rm=TRUE),
              "δO18 mean" = ~ mean(modO18, na.rm=TRUE),
              "δO18 sd" = ~ sd(modO18, na.rm=TRUE))
  )
              
summary_table(iso, my_sum[1])
summary_table(modern, my_sum[2])
```

```{r summary}
sum(!is.na(iso$C13ap))#the ! means it will return the number that is not NA
sum(!is.na(iso$O18ap))
arch_sum<-summarize(iso, meanC13=mean(C13ap, na.rm=TRUE), meanO18=mean(O18ap, na.rm=TRUE), sdC13=sd(C13ap, na.rm=TRUE), sdO18=sd(O18ap, na.rm=TRUE))%>%print()

mod_sum<-summarize(modern, meanC13=mean(modC13, na.rm=TRUE), meanO18=mean(modO18, na.rm=TRUE), seC13=std.error(modC13, na.rm=TRUE), sdO18=sd(modO18, na.rm=TRUE))%>%print()

```


```{r}
stargazer(attitude, header=FALSE)
```

##Step 3
